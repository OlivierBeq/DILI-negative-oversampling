{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T14:23:16.531466600Z",
     "start_time": "2025-04-14T14:23:16.529280400Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Constants."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c15ee73271c80fd2"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ROOT = '.'\n",
    "OUT_FOLDER = f'{ROOT}/results'\n",
    "DATA_FOLDER = f'{ROOT}/data'\n",
    "FILE = f\"{DATA_FOLDER}/Supp. File 1.xlsx\"\n",
    "CHUNKSIZE = 30_000  # Size of chunks for molecular feature calculation\n",
    "N_JOBS = -1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T14:23:20.107153100Z",
     "start_time": "2025-04-14T14:23:20.098636400Z"
    }
   },
   "id": "b7bbf828bd980ee3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Skip if modelling files are present.\n",
    "If you are sure you want to overwrite these files, run the notebook **XX-Advanced_removal_to_run_from_scratch**."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7241bd6aafb9cea7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if os.path.exists(f'{DATA_FOLDER}/Papyrus_05-7_BioSpectra_Mordred-ZscalesVanWesten-descriptors-Reg2SMILES-AllSplitsPROPER-DEVIATION-grouped.feather'):\n",
    "    raise FileExistsError('Files requiring substantial resources are protected. Run the notebook called \"XX-Advanced_removal_to_run_from_scratch\" to force this notebook to run')\n",
    "else:\n",
    "    import pickle\n",
    "    import re\n",
    "    from pathlib import Path\n",
    "    \n",
    "    import pandas as pd\n",
    "    from more_itertools import chunked\n",
    "    from papyrus_scripts import PapyrusDataset\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from pandarallel import pandarallel\n",
    "    from tqdm.auto import tqdm, trange\n",
    "    \n",
    "    from utilities import (ScaffoldSplitter, FrameworkSplitter, generate_scaffold,\n",
    "                           ConnectedComponentsSplitter,\n",
    "                           prepare_biospectra_inputs, prepare_biospectra_inputs_from_papyrus, train_bioactivity_spectra_model, make_biospectra_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T16:37:22.427442600Z",
     "start_time": "2025-04-07T16:37:16.660641Z"
    }
   },
   "id": "106a56c2c2a7d10f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the bioactivity dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c05bcc094a26962"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = (PapyrusDataset(version='05.7', is3d=False, plusplus=False)\n",
    "            .keep_quality('medium')\n",
    "            .to_dataframe(progress=True)\n",
    "            [['connectivity', 'target_id', 'accession', 'SMILES', 'pchembl_value_Mean']]\n",
    "            .query('SMILES != \"C[C+](=O)(Nc1ccccc1)C(C#N)=Cc1cc(O)c(O)cc1\"') # Avoid molecule that RDKit cannot parse\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14a9fcd538baa31b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Organize data splitting schemes: scaffold, framework, random and connected components."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca4b23086257009b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61523ecc53e6cc38"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pandarallel.initialize(progress_bar=True, nb_workers=8, verbose=0)\n",
    "data['murcko_scaffold'] = data.SMILES.parallel_apply(generate_scaffold)\n",
    "data['murcko_cyclic_skeleton'] = data.SMILES.parallel_apply(generate_scaffold, use_csk=True)\n",
    "# Scaffold split\n",
    "train_idx, val_idx, test_idx = ScaffoldSplitter()._split(data, scaffold_list=data.murcko_scaffold, random_state=12345678)\n",
    "data['murcko_scaffold_split'] = (pd.Series(data.index)\n",
    "                                   .mask(data.index.isin(train_idx), 'train')\n",
    "                                   .mask(data.index.isin(val_idx), 'val')\n",
    "                                   .mask(data.index.isin(test_idx), 'test'))\n",
    "# Framework split\n",
    "train_idx, val_idx, test_idx = FrameworkSplitter()._split(data, scaffold_list=data.murcko_cyclic_skeleton, random_state=12345678)\n",
    "data['murcko_cyclic_skeleton_split'] = (pd.Series(data.index)\n",
    "                                          .mask(data.index.isin(train_idx), 'train')\n",
    "                                          .mask(data.index.isin(val_idx), 'val')\n",
    "                                          .mask(data.index.isin(test_idx), 'test'))\n",
    "# Random split\n",
    "train_idx, other = train_test_split(data.index, train_size=0.8, random_state=12345678)\n",
    "val_idx, test_idx = train_test_split(other, train_size=0.5, random_state=12345678)\n",
    "data['random_split'] = (pd.Series(data.index)\n",
    "                          .mask(data.index.isin(train_idx), 'train')\n",
    "                          .mask(data.index.isin(val_idx), 'val')\n",
    "                          .mask(data.index.isin(test_idx), 'test'))\n",
    "# Connected components\n",
    "components = ConnectedComponentsSplitter.get_connected_components(data, 'connectivity', 'accession')\n",
    "train_idx, val_idx, test_idx = ConnectedComponentsSplitter()._split(components, random_state=12345678, tolerance=int(1e-5))\n",
    "data['group'] = components.group\n",
    "data['connected_component_split'] = (pd.Series(data.group)\n",
    "                                     .mask(data.group.isin(train_idx), 'train')\n",
    "                                     .mask(data.group.isin(val_idx), 'val')\n",
    "                                     .mask(data.group.isin(test_idx), 'test'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "919f0694fb5f175e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add absolute deviation values of pChEMBL values from the average pChEMBL value of the protein (based on `target_id`). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d4c8d55255f180"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.concat((data.drop(columns='pchembl_value_Mean'),\n",
    "                  data.pchembl_value_Mean,\n",
    "                  (data.pchembl_value_Mean - data.groupby('target_id').pchembl_value_Mean.transform('mean')).rename('pchembl_value_dev')\n",
    "                  ), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70fae951c35167c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save deviations from average pChEMBL values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70d26af8278c5b71"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "(data.groupby('target_id')\n",
    " .pchembl_value_Mean\n",
    " .agg('mean')\n",
    " .rename('average_pchembl_value_Mean')\n",
    " .to_json(f'{OUT_FOLDER}/Protein_average_Papyrus_05-7_BioSpectra_Mordred-ZscalesVanWesten-descriptors-Reg2SMILES-AllSplitsPROPER-DEVIATION.json')\n",
    " )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T20:25:33.079762200Z",
     "start_time": "2025-04-06T20:25:32.981788700Z"
    }
   },
   "id": "c629756978e78915"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Obtain sequences of the protein targets from the Payrus dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da78ed57c6eacb56"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "protein_targets = (PapyrusDataset.from_dataframe(data, is3d=False, version='05.7', plusplus=False)\n",
    "                   .proteins()\n",
    "                   .to_dataframe())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T16:37:24.068516400Z",
     "start_time": "2025-04-07T16:37:23.864262700Z"
    }
   },
   "id": "8ca035570d8b4c24"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop any compound-protein pair in which proteins have less than 50 amino acids (protein descriptors are not applicable for these)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aba86284ebe41591"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "data = data[data.target_id.isin(protein_targets.query('Sequence.str.len() >= 50').target_id)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T15:01:16.575426100Z",
     "start_time": "2025-04-07T15:01:16.391450100Z"
    }
   },
   "id": "7ed4a2300c705b9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate molecular and protein descriptors altogether. We must use chunks to save memory (since data types cannot be enforced during calculation, only afterwards)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1dc776792ea99313"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data.to_feather(r'C:\\Users\\ojbeq\\Downloads\\save_state_data_for_BS.feather')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T15:01:19.768226300Z",
     "start_time": "2025-04-07T15:01:18.386755300Z"
    }
   },
   "id": "131a8f9234b233a5"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "data= pd.read_feather(r'C:\\Users\\ojbeq\\Downloads\\save_state_data_for_BS.feather')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T07:32:33.796952800Z",
     "start_time": "2025-04-08T07:32:32.197438500Z"
    }
   },
   "id": "c523800d26a0ba68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/57 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a40a08d5824456bb3b9f2f991866900"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = data[['SMILES', 'target_id']].merge(protein_targets[['target_id', 'Sequence']], on='target_id')\n",
    "# Map each chunk back to a `PapyrusDataset` instance, to allow fast access to pre-calculated descriptors. \n",
    "outputs = []\n",
    "for i in trange(0, len(inputs), CHUNKSIZE):\n",
    "    output = pd.concat(prepare_biospectra_inputs_from_papyrus(PapyrusDataset.from_dataframe(data.iloc[i: i+CHUNKSIZE],\n",
    "                                                                                            is3d=False,\n",
    "                                                                                            version='05.7',\n",
    "                                                                                            plusplus=False,\n",
    "                                                                                            chunksize=500_000),\n",
    "                                                              know_sequences=False,\n",
    "                                                              data_folder=DATA_FOLDER),\n",
    "                       axis=0, ignore_index=True)\n",
    "    id_col = output[['connectivity', 'target_id']]\n",
    "    output = (output.drop(columns=['connectivity', 'target_id'])\n",
    "              .apply(pd.to_numeric, downcast='integer')\n",
    "              .apply(pd.to_numeric, downcast='float'))\n",
    "    output = pd.concat((id_col, output), axis=1)\n",
    "    outputs.append(output)\n",
    "outputs = pd.concat(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-08T07:32:34.840906800Z"
    }
   },
   "id": "6d64656a0f1df8fb"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "data = pd.concat((data.reset_index(), outputs), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T07:27:14.093326200Z",
     "start_time": "2025-04-08T07:27:08.646701300Z"
    }
   },
   "id": "fc7edc275d156f3e"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(1703748, 1764)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T07:27:33.949890100Z",
     "start_time": "2025-04-08T07:27:33.939149400Z"
    }
   },
   "id": "7e5d7e8c9aefec8e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data.to_feather(f'{DATA_FOLDER}/Papyrus_05-7_BioSpectra_Mordred-ZscalesVanWesten-descriptors-Reg2SMILES-AllSplitsPROPER-DEVIATION-grouped.feather')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T07:26:02.844516700Z",
     "start_time": "2025-04-08T07:26:01.267650400Z"
    }
   },
   "id": "760e7b85ee0e3961"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train bioactivity spectra models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ced9180a5c1cd93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for short_split_name, split_type in (('scaffold', 'murcko_scaffold_split'),\n",
    "                                     ('framework', 'murcko_cyclic_skeleton_split'),\n",
    "                                     ('random', 'random_split'),\n",
    "                                     ('doublecold', 'non_overlappling_split')):\n",
    "    for short_activity_name, activity_type in (('mean', 'pchembl_value_Mean'),\n",
    "                                               ('dev', 'pchembl_value_dev')):\n",
    "        os.makedirs(f'{OUT_FOLDER}/{short_split_name}_{short_activity_name}', exist_ok=True)\n",
    "        train_bioactivity_spectra_model(data,\n",
    "                                        split_type=split_type,\n",
    "                                        activity_type=activity_type,\n",
    "                                        model_type='PCM',\n",
    "                                        out_folder=f'{DATA_FOLDER}/{short_split_name}_{short_activity_name}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c7d4e9df639bd30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Determine the model with highest R² to be used for inference."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7fdca5a9ffde578"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from more_itertools import chunked\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utilities import (prepare_biospectra_inputs, make_biospectra_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T14:23:32.598283900Z",
     "start_time": "2025-04-14T14:23:28.725500900Z"
    }
   },
   "id": "905cdbe563dfef16"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "  data splitting scheme pChEMBL value  Best Training Epoch  Validation MSE  \\\n0              scaffold          mean                 2474           0.464   \n1              scaffold           dev                 2612           0.445   \n2             framework          mean                 2231           0.470   \n3             framework           dev                 1636           0.449   \n4                random          mean                 3119           0.353   \n5                random           dev                 1831           0.347   \n6            doublecold          mean                    9           2.001   \n7            doublecold           dev                  851           0.934   \n\n   Validation R2  Validation Pearson  Test MSE  Test R2  Test Pearson  \n0          0.752               0.868     0.473    0.749         0.866  \n1          0.579               0.762     0.457    0.587         0.767  \n2          0.745               0.864     0.487    0.734         0.857  \n3          0.573               0.758     0.468    0.556         0.747  \n4          0.805               0.900     0.347    0.808         0.900  \n5          0.668               0.818     0.347    0.669         0.818  \n6          0.148               0.509     1.917   -0.334         0.220  \n7         -0.244               0.126     0.790   -1.019         0.023  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data splitting scheme</th>\n      <th>pChEMBL value</th>\n      <th>Best Training Epoch</th>\n      <th>Validation MSE</th>\n      <th>Validation R2</th>\n      <th>Validation Pearson</th>\n      <th>Test MSE</th>\n      <th>Test R2</th>\n      <th>Test Pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>scaffold</td>\n      <td>mean</td>\n      <td>2474</td>\n      <td>0.464</td>\n      <td>0.752</td>\n      <td>0.868</td>\n      <td>0.473</td>\n      <td>0.749</td>\n      <td>0.866</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scaffold</td>\n      <td>dev</td>\n      <td>2612</td>\n      <td>0.445</td>\n      <td>0.579</td>\n      <td>0.762</td>\n      <td>0.457</td>\n      <td>0.587</td>\n      <td>0.767</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>framework</td>\n      <td>mean</td>\n      <td>2231</td>\n      <td>0.470</td>\n      <td>0.745</td>\n      <td>0.864</td>\n      <td>0.487</td>\n      <td>0.734</td>\n      <td>0.857</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>framework</td>\n      <td>dev</td>\n      <td>1636</td>\n      <td>0.449</td>\n      <td>0.573</td>\n      <td>0.758</td>\n      <td>0.468</td>\n      <td>0.556</td>\n      <td>0.747</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>random</td>\n      <td>mean</td>\n      <td>3119</td>\n      <td>0.353</td>\n      <td>0.805</td>\n      <td>0.900</td>\n      <td>0.347</td>\n      <td>0.808</td>\n      <td>0.900</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>random</td>\n      <td>dev</td>\n      <td>1831</td>\n      <td>0.347</td>\n      <td>0.668</td>\n      <td>0.818</td>\n      <td>0.347</td>\n      <td>0.669</td>\n      <td>0.818</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>doublecold</td>\n      <td>mean</td>\n      <td>9</td>\n      <td>2.001</td>\n      <td>0.148</td>\n      <td>0.509</td>\n      <td>1.917</td>\n      <td>-0.334</td>\n      <td>0.220</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>doublecold</td>\n      <td>dev</td>\n      <td>851</td>\n      <td>0.934</td>\n      <td>-0.244</td>\n      <td>0.126</td>\n      <td>0.790</td>\n      <td>-1.019</td>\n      <td>0.023</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_holdout = re.compile(r\"^Holdout test:\\s+MSE Loss: (-?\\d+\\.\\d+)\\s+R²: (-?\\d+\\.\\d+)\\s+Pearson's r: (-?\\d+\\.\\d+)$\")\n",
    "pattern_best_epoch= re.compile(r\"^No loss improvement in the last \\d+ epochs: minimum loss = -?\\d+\\.\\d+ from epoch (\\d+)$\")\n",
    "pattern_validation= re.compile(r\"^\\s+Epoch (\\d+) \\(validation\\):\\s+MSE Loss: (-?\\d+\\.\\d+)\\s+R²: (-?\\d+\\.\\d+)\\s+Pearson's r: (-?\\d+\\.\\d+)$\")\n",
    "performances = []\n",
    "for short_split_name, split_type in (('scaffold', 'murcko_scaffold_split'),\n",
    "                                     ('framework', 'murcko_cyclic_skeleton_split'),\n",
    "                                     ('random', 'random_split'),\n",
    "                                     ('doublecold', 'non_overlappling_split')):\n",
    "    for short_activity_name, activity_type in (('mean', 'pchembl_value_Mean'),\n",
    "                                               ('dev', 'pchembl_value_dev')):\n",
    "        log_file = next(Path(f'{DATA_FOLDER}/{short_split_name}_{short_activity_name}').glob('*.log'))\n",
    "        with open(log_file, encoding=\"UTF-8\") as fh:\n",
    "            # Find metrics on validation set\n",
    "            val_values = (pd.DataFrame([match.groups() for line in fh if (match := pattern_validation.search(line))],\n",
    "                                       columns=['Best Training Epoch', 'Validation MSE', 'Validation R2', 'Validation Pearson'])\n",
    "                            .astype({'Best Training Epoch': int, 'Validation MSE': float, 'Validation R2': float, 'Validation Pearson': float}))\n",
    "            fh.seek(0)\n",
    "            # Find the epoch with the best validation loss\n",
    "            best_epoch = int([match.groups() for line in fh if (match := pattern_best_epoch.search(line))][0][0])\n",
    "            fh.seek(0)\n",
    "            # Find metrics on holdout set\n",
    "            holdout_values = (pd.DataFrame([match.groups() for line in fh if (match := pattern_holdout.search(line))],\n",
    "                                           columns=['Test MSE', 'Test R2', 'Test Pearson'])\n",
    "                              .astype({'Test MSE': float, 'Test R2': float, 'Test Pearson': float}))\n",
    "            # Aggregate\n",
    "            performances.append(pd.concat((pd.DataFrame([{'data splitting scheme': short_split_name, 'pChEMBL value': short_activity_name}]),\n",
    "                                           val_values.query('`Best Training Epoch` == @best_epoch').reset_index(drop=True),\n",
    "                                           holdout_values), axis=1))\n",
    "\n",
    "performances = pd.concat(performances, ignore_index=True)\n",
    "performances"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T14:44:45.904597600Z",
     "start_time": "2025-04-14T14:44:45.814842800Z"
    }
   },
   "id": "84931790bacb5349"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The random split model predicting mean values will be used for bioactivity spectrum prediction as it shows the best performance and no extrapolation capacity to new proteins will be performed (the proteins making up the spetrum will remain constant)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64f496819f8577b8"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "model_prefix = next(Path(f'{DATA_FOLDER}/random_mean').glob('*.pkg')).absolute().as_posix().replace('.pkg', '')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T14:44:58.447129300Z",
     "start_time": "2025-04-14T14:44:58.431985700Z"
    }
   },
   "id": "3150d03bad34afdc"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "data_mols = pd.read_excel(FILE, sheet_name='Original Dataset MolDescs',\n",
    "                          usecols=['InChIKey', 'SMILES', 'ALogP', 'Molecular_Weight', 'Molecular_Solubility', 'H_Count', 'C_Count',\n",
    "                                   'N_Count', 'O_Count', 'F_Count', 'S_Count', 'Cl_Count', 'Num_H_Acceptors_Lipinski', 'Num_H_Donors_Lipinski', 'JY', 'Wiener',\n",
    "                                   'CHI_V_3_P', 'CHI_V_3_C', 'ES_Sum_sCH3', 'ES_Sum_ssCH2', 'ES_Sum_dsCH', 'ES_Sum_aaCH', 'ES_Sum_sssCH', 'ES_Sum_dssC', 'ES_Sum_aasC',\n",
    "                                   'ES_Sum_aaaC', 'ES_Sum_ssssC', 'ES_Sum_sNH2', 'ES_Sum_ssNH', 'ES_Sum_aaN', 'ES_Sum_sssN', 'ES_Sum_ddsN', 'ES_Sum_sOH', 'ES_Sum_dO',\n",
    "                                   'ES_Sum_ssO', 'ES_Sum_ssS', 'Kappa_3_AM', 'PHI', 'ECFP_6'])\n",
    "comp_mols = pd.read_excel(FILE, sheet_name='Additional Set MolDescs',\n",
    "                          usecols=['SMILES', 'binaryDILI', 'vDILIConcern', 'ALogP', 'Molecular_Weight', 'Molecular_Solubility', 'H_Count', 'C_Count',\n",
    "                                   'N_Count', 'O_Count', 'F_Count', 'S_Count', 'Cl_Count', 'Num_H_Acceptors_Lipinski', 'Num_H_Donors_Lipinski', 'JY', 'Wiener',\n",
    "                                   'CHI_V_3_P', 'CHI_V_3_C', 'ES_Sum_sCH3', 'ES_Sum_ssCH2', 'ES_Sum_dsCH', 'ES_Sum_aaCH', 'ES_Sum_sssCH', 'ES_Sum_dssC', 'ES_Sum_aasC',\n",
    "                                   'ES_Sum_aaaC', 'ES_Sum_ssssC', 'ES_Sum_sNH2', 'ES_Sum_ssNH', 'ES_Sum_aaN', 'ES_Sum_sssN', 'ES_Sum_ddsN', 'ES_Sum_sOH', 'ES_Sum_dO',\n",
    "                                   'ES_Sum_ssO', 'ES_Sum_ssS', 'Kappa_3_AM', 'PHI', 'ECFP_6'])\n",
    "\n",
    "ECFP6 = (data_mols['ECFP_6']\n",
    "             .apply(list)\n",
    "             .apply(pd.Series)\n",
    "             .astype(int)\n",
    "             .rename_axis(index=None, columns=None)\n",
    "             .rename(columns=lambda x: f'ECFP_6_{x+1}'))\n",
    "\n",
    "data_mols = pd.concat((data_mols.drop(columns=['ECFP_6']), ECFP6),\n",
    "                      axis=1)\n",
    "\n",
    "ECFP6 = (comp_mols['ECFP_6']\n",
    "             .apply(list)\n",
    "             .apply(pd.Series)\n",
    "             .astype(int)\n",
    "             .rename_axis(index=None, columns=None)\n",
    "             .rename(columns=lambda x: f'ECFP_6_{x+1}'))\n",
    "\n",
    "comp_mols = pd.concat((comp_mols.drop(columns=['ECFP_6']), ECFP6),\n",
    "                      axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T14:45:00.405853700Z",
     "start_time": "2025-04-14T14:44:59.359331600Z"
    }
   },
   "id": "2611af24fb2452b1"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa6d5bfbca2e41d0afafb01379a15c77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "for chunk in tqdm(chunked(data_mols.SMILES.drop_duplicates(),n=10), total=-(-len(data_mols) // 10)):\n",
    "    inputs = prepare_biospectra_inputs(smiles=chunk, know_sequences=True, data_folder=DATA_FOLDER, verbose=False)\n",
    "    predictions.append(pd.concat((inputs[['SMILES', 'target_id']],\n",
    "                              make_biospectra_predictions(inputs.drop(columns=['SMILES', 'target_id']),\n",
    "                                                          model_prefix=model_prefix,\n",
    "                                                          verbose=False)), axis=1)\n",
    "                         .pivot(index='SMILES', columns='target_id')\n",
    "                         .reset_index())\n",
    "\n",
    "predictions = pd.concat(predictions, ignore_index=True)\n",
    "predictions.columns = [col[0] if i == 0 else col[1] for i, col in enumerate(predictions.columns)]\n",
    "data_chem_biospectra = data_mols.merge(predictions, on='SMILES').drop(columns='SMILES')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T14:52:40.659561800Z",
     "start_time": "2025-04-14T14:45:20.031540900Z"
    }
   },
   "id": "fa747b9d439621c2"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/25 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "becbcfd5b3de421a94874887233dd7c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "for chunk in tqdm(chunked(comp_mols.SMILES.drop_duplicates(),n=10), total=-(-len(comp_mols) // 10)):\n",
    "    inputs = prepare_biospectra_inputs(smiles=chunk, know_sequences=True, data_folder=DATA_FOLDER, verbose=False)\n",
    "    predictions.append(pd.concat((inputs[['SMILES', 'target_id']],\n",
    "                              make_biospectra_predictions(inputs.drop(columns=['SMILES', 'target_id']),\n",
    "                                                          model_prefix=model_prefix,\n",
    "                                                          verbose=False)), axis=1)\n",
    "                         .pivot(index='SMILES', columns='target_id')\n",
    "                         .reset_index())\n",
    "\n",
    "predictions = pd.concat(predictions, ignore_index=True)\n",
    "predictions.columns = [col[0] if i == 0 else col[1] for i, col in enumerate(predictions.columns)]\n",
    "comp_data_biospectra = comp_mols.merge(predictions, on='SMILES').drop(columns='SMILES')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T15:08:46.250863900Z",
     "start_time": "2025-04-14T14:52:40.659561800Z"
    }
   },
   "id": "eba9d48cceeae119"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save to disk.\n",
    "These values are those in the last tab of `Supp. File. 1.xlsx` "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7373f0aeaf1cb95e"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "with open(f'{OUT_FOLDER}/data_chem_biospectra_from_scratch.pkl', 'wb') as oh:\n",
    "    pickle.dump(data_chem_biospectra, oh)\n",
    "with open(f'{OUT_FOLDER}/comp_data_biospectra_from_scratch.pkl', 'wb') as oh:\n",
    "    pickle.dump(comp_data_biospectra, oh)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T15:10:46.443353700Z",
     "start_time": "2025-04-14T15:10:46.412746300Z"
    }
   },
   "id": "8e528748da06fd49"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
